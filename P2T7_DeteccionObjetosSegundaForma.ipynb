{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeteccionObjetosSegundaForma.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRMoheR48XSo",
        "colab_type": "text"
      },
      "source": [
        "##Paso #0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANSVPITfpITU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==1.15"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-vwbXYmq0So",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krMHcC4DrrNr",
        "colab_type": "code",
        "outputId": "e8ad0fbb-af96-411c-b684-6e9ae863bfb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "!pip install -q pycocotools\n",
        "!pip install -q watermark \n",
        "!pip install tf_slim"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf_slim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf_slim) (0.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py>=0.2.2->tf_slim) (1.12.0)\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gdmKzTPslgK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 --version\n",
        "%load_ext watermark\n",
        "print(\"--Computer vision(hardware)--\")\n",
        "%watermark\n",
        "%watermark -a \"--Computer vision(libraries)--\" -u -d -v -p numpy,tensorflow,pycocotools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUjuZxNysuD9",
        "colab_type": "code",
        "outputId": "da3c8752-eabf-44a9-9360-c51c1f91da31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print('GPU NO esta activa para el entorno')\n",
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU NO esta activa para el entorno\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNKryyX6s5AF",
        "colab_type": "code",
        "outputId": "57350d5e-3be4-47eb-bdeb-0bd60caa7dcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-14-4996ee3d8d09>\", line 2, in <module>\n",
            "    drive.mount('/content/gdrive')\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\", line 224, in mount\n",
            "    drive_exited,\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pexpect/spawnbase.py\", line 344, in expect\n",
            "    timeout, searchwindowsize, async_)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pexpect/spawnbase.py\", line 372, in expect_list\n",
            "    return exp.expect_loop(timeout)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pexpect/expect.py\", line 177, in expect_loop\n",
            "    timeout = end_time - time.time()\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 733, in getmodule\n",
            "    if ismodule(module) and hasattr(module, '__file__'):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\", line 50, in __getattr__\n",
            "    module = self._load()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\", line 44, in _load\n",
            "    module = _importlib.import_module(self.__name__)\n",
            "  File \"/usr/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/__init__.py\", line 47, in <module>\n",
            "    from tensorflow.contrib import distributions\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/distributions/__init__.py\", line 29, in <module>\n",
            "    from tensorflow.contrib.distributions.python.ops import bijectors\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/distributions/__init__.py\", line 44, in <module>\n",
            "    from tensorflow.contrib.distributions.python.ops.estimator import *\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/distributions/python/ops/estimator.py\", line 21, in <module>\n",
            "    from tensorflow.contrib.learn.python.learn.estimators.head import _compute_weighted_loss\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/__init__.py\", line 93, in <module>\n",
            "    from tensorflow.contrib.learn.python.learn import *\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/__init__.py\", line 28, in <module>\n",
            "    from tensorflow.contrib.learn.python.learn import *\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/__init__.py\", line 30, in <module>\n",
            "    from tensorflow.contrib.learn.python.learn import estimators\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/estimators/__init__.py\", line 302, in <module>\n",
            "    from tensorflow.contrib.learn.python.learn.estimators.dnn import DNNClassifier\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/estimators/dnn.py\", line 34, in <module>\n",
            "    from tensorflow.contrib.learn.python.learn.estimators import dnn_linear_combined\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/estimators/dnn_linear_combined.py\", line 36, in <module>\n",
            "    from tensorflow.contrib.learn.python.learn.estimators import estimator\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py\", line 52, in <module>\n",
            "    from tensorflow.contrib.learn.python.learn.learn_io import data_feeder\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/learn_io/__init__.py\", line 26, in <module>\n",
            "    from tensorflow.contrib.learn.python.learn.learn_io.dask_io import extract_dask_data\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/learn_io/dask_io.py\", line 33, in <module>\n",
            "    import dask.dataframe as dd\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/dask/dataframe/__init__.py\", line 13, in <module>\n",
            "    from .io import (\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/dask/dataframe/io/__init__.py\", line 15, in <module>\n",
            "    from .sql import read_sql_table\n",
            "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 674, in exec_module\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 764, in get_code\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 832, in get_data\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53cjIajk8pYS",
        "colab_type": "text"
      },
      "source": [
        "## Paso #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feuAnk5W8pWf",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZUhjEWjtX-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#descargamos el repositorio de object_detection que esta en GITHUB\n",
        "%cd /content/gdrive/My\\ Drive/deteccionDeObjectos\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "#cambiamos la variable de entorno para que sea ahora la del repositorio clonado\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/gdrive/My Drive/deteccionDeObjectos/models/research/:/content/gdrive/My Drive/deteccionDeObjectos/models/research/slim/'\n",
        "#compliamos protos\n",
        "%cd /content/gdrive/My\\ Drive/deteccionDeObjectos/models/research\n",
        "#compilar protos (generar los archivos .py que van en la carpeta protos/)\n",
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOULjSqF9OBB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#variables con las rutas de nuestras dataset de entrenamiento\n",
        "test_record_fname     = '/content/gdrive/My Drive/deteccionDeObjectos/TFRecords/test.record'\n",
        "train_record_fname    = '/content/gdrive/My Drive/deteccionDeObjectos/TFRecords/train.record'\n",
        "label_map_pbtxt_fname = '/content/gdrive/My Drive/deteccionDeObjectos/configuracion/label_map.pbtxt'\n",
        "\n",
        "# número de pasos (epochs) que usaremos para entrenar\n",
        "num_steps = 2000  # 200000\n",
        "\n",
        "# número de evaluaciones por pasos (cada 50 pasos evaluamos el modelo).\n",
        "num_eval_steps = 50\n",
        "\n",
        "# Selecionamos el archivo de configuración del modelo\n",
        "selected_model = 'ssd_mobilenet_v2'\n",
        "\n",
        "MODELS_CONFIG = {\n",
        "    'ssd_mobilenet_v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
        "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'faster_rcnn_inception_v2': {\n",
        "        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
        "        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'rfcn_resnet101': {\n",
        "        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n",
        "        'pipeline_file': 'rfcn_resnet101_pets.config',\n",
        "        'batch_size': 8\n",
        "    }\n",
        "}\n",
        "\n",
        "# definimos el tamaño del lote de entrenamiento para uso en la memoria de \n",
        "# la GPU Tesla K80 de Colaborate para el modelo seleccionado.\n",
        "batch_size = MODELS_CONFIG[selected_model]['batch_size']\n",
        "\n",
        "# Nombre del modelo de detección de objectos que usaremos\n",
        "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
        "\n",
        "# Nombre del archivo de canalización en la API de detección de objetos de tensorflow.\n",
        "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
        "\n",
        "pipeline_fname = os.path.join('/content/gdrive/My Drive/deteccionDeObjectos/models/research/object_detection/samples/configs/', pipeline_file)\n",
        "print(\"pipeline_fname:\"+pipeline_fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qE-gE5qU9chI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ubicación de la carpeta base\n",
        "%cd /content/gdrive/My\\ Drive/deteccionDeObjectos/models/research\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib.request\n",
        "import tarfile\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "\n",
        "# ubicación donde guardaremos el grafo preentrenado que descargamos\n",
        "DEST_DIR = '/content/gdrive/My Drive/deteccionDeObjectos/models/research/pretrained_model'\n",
        "\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "  shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)\n",
        "\n",
        "# listamos los archivos descargados\n",
        "!echo $DEST_DIR\n",
        "!ls -alh pretrained_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1vH_C4X9o3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Nombre del archivo de canalización en la API de detección de objetos de tensorflow.\n",
        "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
        "\n",
        "pipeline_fname = os.path.join('/content/gdrive/My Drive/deteccionDeObjectos/models/research/object_detection/samples/configs/', pipeline_file)\n",
        "print(\"pipeline_fname:\"+pipeline_fname)\n",
        "\n",
        "fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n",
        "fine_tune_checkpoint\n",
        "%cd /content/gdrive/My\\ Drive/deteccionDeObjectos/models/research"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IS2Ca96d99gn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "15be67b0-b2a5-4cc2-a99c-330e6703bd91"
      },
      "source": [
        "import os\n",
        "\n",
        "assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)\n",
        "\n",
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-8b2d87e3209e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'`{}` not exist'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_num_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpbtxt_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pipeline_fname' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLxvfUX9-Cq6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "0f00791a-8202-4fec-a5e7-963c45f0af9e"
      },
      "source": [
        "import re\n",
        "\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open(pipeline_fname, 'w') as f:\n",
        "    \n",
        "    # punto de control de inicio\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"','fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "    \n",
        "    # ubicación de los tfrecords de train y test\n",
        "    s = re.sub('(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub('(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
        "\n",
        "    # ubicación del labelmap.pbtxt\n",
        "    s = re.sub('label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Establecemos el tamaño del lote de entrenamiento\n",
        "    s = re.sub('batch_size: [0-9]+','batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Establecemos la cantidad de pasos de entrenamiento\n",
        "    s = re.sub('num_steps: [0-9]+','num_steps: {}'.format(num_steps), s)\n",
        "    \n",
        "    # establecemos el número de clases (etiquetas)\n",
        "    s = re.sub('num_classes: [0-9]+','num_classes: {}'.format(num_classes), s)\n",
        "    f.write(s)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-3acf99a47c80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_num_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_map_pbtxt_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline_fname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_num_classes' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmP0plpW-Dof",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(pipeline_fname)\n",
        "!cat pipeline_fname\n",
        "!cat /content/gdrive/My\\ Drive/deteccionDeObjectos/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-BH5BCy-HTQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_dir = '/content/gdrive/My Drive/deteccionDeObjectos/models/research/training/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IX7a9jCV-Y33",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convierte los archivos xml que estan en la carpeta de entrenamiento a una lista CSV \n",
        "# y genera el archivo label_map.pbtxt en el directorio configuracion\n",
        "!python /content/gdrive/My\\ Drive/deteccionDeObjectos/xml_a_csv_v2.py \\\n",
        "--inputDir /content/gdrive/My\\ Drive/deteccionDeObjectos/img_entrenamiento \\\n",
        "--outputFile /content/gdrive/My\\ Drive/deteccionDeObjectos/csv/train_labels.csv \\\n",
        "--labelMapDir /content/gdrive/My\\ Drive/deteccionDeObjectos/configuracion"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9w6v_Wu--f-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convierte los archivos xml que estan en la carpeta de test a una lista CSV\n",
        "!python /content/gdrive/My\\ Drive/deteccionDeObjectos/xml_a_csv_v2.py \\\n",
        "--inputDir /content/gdrive/My\\ Drive/deteccionDeObjectos/img_test \\\n",
        "--outputFile /content/gdrive/My\\ Drive/deteccionDeObjectos/csv/test_labels.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxtPhW27-kTP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generando el archivo  train.record\n",
        "!python /content/gdrive/My\\ Drive/deteccionDeObjectos/csv_a_tf_v2.py \\\n",
        "--csv_input=/content/gdrive/My\\ Drive/deteccionDeObjectos/csv/train_labels.csv \\\n",
        "--output_path=/content/gdrive/My\\ Drive/deteccionDeObjectos/TFRecords/train.record \\\n",
        "--img_path=/content/gdrive/My\\ Drive/deteccionDeObjectos/img_entrenamiento \\\n",
        "--label_map /content/gdrive/My\\ Drive/deteccionDeObjectos/configuracion/label_map.pbtxt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diqtXiZS-pUy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generando el archivo  test.record\n",
        "!python /content/gdrive/My\\ Drive/deteccionDeObjectos/csv_a_tf_v2.py \\\n",
        "--csv_input /content/gdrive/My\\ Drive/deteccionDeObjectos/csv/test_labels.csv \\\n",
        "--output_path /content/gdrive/My\\ Drive/deteccionDeObjectos/TFRecords/test.record \\\n",
        "--img_path /content/gdrive/My\\ Drive/deteccionDeObjectos/img_test \\\n",
        "--label_map /content/gdrive/My\\ Drive/deteccionDeObjectos/configuracion/label_map.pbtxt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxEVdWdh-p4f",
        "colab_type": "text"
      },
      "source": [
        "##Paso #2\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0TJs76r-twX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ['PYTHONPATH'] = '/env/python:/content/gdrive/My Drive/deteccionDeObjectos/models/research/:/content/gdrive/My Drive/deteccionDeObjectos/models/research/slim/'\n",
        "#os.environ['PYTHONPATH'] =   '/content/gdrive/My Drive/deteccionDeObjectos/models/research'\n",
        "#os.environ['PYTHONPATH'] += ':/content/gdrive/My Drive/deteccionDeObjectos/models/research/slim'\n",
        "#os.environ['PYTHONPATH'] += ':/content/gdrive/My Drive/deteccionDeObjectos/models/research/object_detection/protos'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OFkwroe-zwG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!echo $PYTHONPATH"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Od2RSSDR-0Qs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#variables con las rutas de nuestras dataset de entrenamiento\n",
        "test_record_fname     = '/content/gdrive/My Drive/deteccionDeObjectos/TFRecords/test.record'\n",
        "train_record_fname    = '/content/gdrive/My Drive/deteccionDeObjectos/TFRecords/train.record'\n",
        "label_map_pbtxt_fname = '/content/gdrive/My Drive/deteccionDeObjectos/configuracion/label_map.pbtxt'\n",
        "\n",
        "# número de pasos (epochs) que usaremos para entrenar\n",
        "num_steps = 2000  # 200000\n",
        "\n",
        "# número de evaluaciones por pasos (cada 50 pasos evaluamos el modelo).\n",
        "num_eval_steps = 50\n",
        "\n",
        "# Selecionamos el archivo de configuración del modelo\n",
        "selected_model = 'ssd_mobilenet_v2'\n",
        "\n",
        "MODELS_CONFIG = {\n",
        "    'ssd_mobilenet_v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
        "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'faster_rcnn_inception_v2': {\n",
        "        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
        "        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'rfcn_resnet101': {\n",
        "        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n",
        "        'pipeline_file': 'rfcn_resnet101_pets.config',\n",
        "        'batch_size': 8\n",
        "    }\n",
        "}\n",
        "\n",
        "# definimos el tamaño del lote de entrenamiento para uso en la memoria de \n",
        "# la GPU Tesla K80 de Colaborate para el modelo seleccionado.\n",
        "batch_size = MODELS_CONFIG[selected_model]['batch_size']\n",
        "\n",
        "# Nombre del modelo de detección de objectos que usaremos\n",
        "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
        "\n",
        "# Nombre del archivo de canalización en la API de detección de objetos de tensorflow.\n",
        "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
        "\n",
        "pipeline_fname = os.path.join('/content/gdrive/My Drive/deteccionDeObjectos/models/research/object_detection/samples/configs/', pipeline_file)\n",
        "print(\"pipeline_fname:\"+pipeline_fname)\n",
        "\n",
        "model_dir = '/content/gdrive/My Drive/deteccionDeObjectos/models/research/training/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7Z2WIgv-3Rt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Recuerden este codigo se hace una sola vez (de lo contrario perderan el entrenamiento)\n",
        "# la carpeta se debe crear en /content/gdrive/My Drive/deteccionDeObjectos/models/research/\n",
        "!rm -rf {model_dir}\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "print(model_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sc-xUY8l-3PW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#descargar y descomprimir el servidor de tensorboard\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epzAUcN__BhM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LOG_DIR = model_dir\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format('/content/gdrive/My Drive/deteccionDeObjectos/models/research/training/')\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hteUswBL_CT-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1i-Dn6n5_Gqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorboardcolab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtVw5VeF_IlK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tbc=TensorBoardColab()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y47DTecn_NYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jicAUpAc_NV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#aca podemos revisar algunos de los parametros que vamos a tener presente para entrenar\n",
        "print (\"---archivos necesarios para el entremiento---\\n\")\n",
        "print(\"pipeline_fname: \"+pipeline_fname)\n",
        "print(\"model_dir: \"+model_dir)\n",
        "print(\"\\n---parametros para el entrenamiento---\")\n",
        "print(\"num_steps: \"+str(num_steps))\n",
        "print(\"num_eval_steps: \"+str(num_eval_steps))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBiviCeB_NR8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python /content/gdrive/My\\ Drive/deteccionDeObjectos/models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path /content/gdrive/My\\ Drive/deteccionDeObjectos/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config \\\n",
        "    --model_dir  /content/gdrive/My\\ Drive/deteccionDeObjectos/models/research/training/ \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps 2000 \\\n",
        "    --num_eval_steps 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzFuyh2I_NPF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content\n",
        "# Forma de entrenamiento heredada (también funciona y mucho mejor).\n",
        "!python /content/gdrive/My\\ Drive/deteccionDeObjectos/models/research/deteccionDeObjectos/legacy/train.py \\\n",
        "--alsologtostderr \\\n",
        "--train_dir /content/gdrive/My\\ Drive/deteccionDeObjectos/models/research/training \\\n",
        "--pipeline_config_path /content/gdrive/My\\ Drive/deteccionDeObjectos/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config\n",
        "\n",
        "# !python /content/gdrive/My\\ Drive/deteccionDeObjectos/models/research/object_detection/legacy/train.py --logtostderr --train_dir /content/gdrive/My\\ Drive/deteccionDeObjectos/models/research/training/ --pipeline_config_path content/gdrive/My\\ Drive/deteccionDeObjectos/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-jq5A8l_a_q",
        "colab_type": "text"
      },
      "source": [
        "##Paso #3\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GMvPqJU_NNs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#eliminamos la carpeta donde se guarda el grafo inferencial congelado\n",
        "import shutil\n",
        "shutil.rmtree('/content/gdrive/My Drive/deteccionDeObjectos/models/research/fine_tuned_model')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAWLLLj4_NKe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#generamos el nombre el ultimo checkpoint valido de entrenamiento\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "%cd /content/gdrive/My\\ Drive/deteccionDeObjectos/models/research\n",
        "\n",
        "output_directory = '/content/gdrive/My Drive/deteccionDeObjectos/models/research/fine_tuned_model'\n",
        "\n",
        "lst = os.listdir(model_dir)\n",
        "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
        "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
        "last_model = lst[steps.argmax()].replace('.meta', '')\n",
        "\n",
        "last_model_path = os.path.join(model_dir, last_model)\n",
        "print(last_model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhw1xmv7_NFb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#generamos el grafo inferencias congelado\n",
        "!python /content/gdrive/My\\ Drive/deteccionDeObjectos/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path='/content/gdrive/My Drive/deteccionDeObjectos/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config' \\\n",
        "    --output_directory='/content/gdrive/My Drive/deteccionDeObjectos/models/research/fine_tuned_model' \\\n",
        "    --trained_checkpoint_prefix='/content/gdrive/My Drive/deteccionDeObjectos/models/research/training/model.ckpt-758'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlNWH4XJ_utg",
        "colab_type": "text"
      },
      "source": [
        "##Paso #4\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ir54OHWg_NEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "output_directory='/content/gdrive/My Drive/deteccionDeObjectos/models/research/fine_tuned_model'\n",
        "pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")\n",
        "\n",
        "assert os.path.isfile(pb_fname), '`{}` not exist'.format(pb_fname)\n",
        "!ls -alh {pb_fname}\n",
        "from google.colab import files\n",
        "#descargamos el modelo\n",
        "files.download(pb_fname)\n",
        "#descargamos el mapa de etiquetas.\n",
        "files.download(label_map_pbtxt_fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izIGAzEp_zfn",
        "colab_type": "text"
      },
      "source": [
        "##Paso #5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NTLTBqN_NBE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# Ruta del gráfo de detección congelado. Este es el modelo real que se utiliza para la detección de objetos.\n",
        "PATH_TO_CKPT = pb_fname\n",
        "\n",
        "# Lista de las cadenas que se utilizan para agregar la etiqueta correcta para cada cuadro.\n",
        "PATH_TO_LABELS = label_map_pbtxt_fname\n",
        "\n",
        "# ruta donde estan las imágenes para probar\n",
        "PATH_TO_TEST_IMAGES_DIR =  \"/content/gdrive/My Drive/deteccionDeObjectos/img_prueba\"\n",
        "\n",
        "assert os.path.isfile(pb_fname)\n",
        "assert os.path.isfile(PATH_TO_LABELS)\n",
        "TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, \"*.*\"))\n",
        "assert len(TEST_IMAGE_PATHS) > 0, 'No image found in `{}`.'.format(PATH_TO_TEST_IMAGES_DIR)\n",
        "print(TEST_IMAGE_PATHS)\n",
        "\n",
        "#número de clases a las que se liminara el grafo.\n",
        "num_classes = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdO0d2zk_M6N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/gdrive/My\\ Drive/deteccionDeObjectos/models/research/object_detection\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "sys.path.append(\"..\")\n",
        "from object_detection.utils import ops as utils_ops\n",
        "\n",
        "#Esto es necesario para mostrar las imágenes.\n",
        "%matplotlib inline\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "  od_graph_def = tf.GraphDef()\n",
        "  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "    serialized_graph = fid.read()\n",
        "    od_graph_def.ParseFromString(serialized_graph)\n",
        "    tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=num_classes, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "def load_image_into_numpy_array(image):\n",
        "    (im_width, im_height) = image.size\n",
        "    return np.array(image.getdata()).reshape(\n",
        "        (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "# Size, in inches, of the output images.\n",
        "IMAGE_SIZE = (12, 8)\n",
        "\n",
        "#funcion para analizar inferencia en una imagen\n",
        "def run_inference_for_single_image(image, graph):\n",
        "    with graph.as_default():\n",
        "        with tf.Session() as sess:\n",
        "            # Obtenga manijas para tensores de entrada y salida\n",
        "            ops = tf.get_default_graph().get_operations()\n",
        "            all_tensor_names = {\n",
        "                output.name for op in ops for output in op.outputs}\n",
        "            tensor_dict = {}\n",
        "            for key in [\n",
        "                'num_detections', 'detection_boxes', 'detection_scores',\n",
        "                'detection_classes', 'detection_masks'\n",
        "            ]:\n",
        "                tensor_name = key + ':0'\n",
        "                if tensor_name in all_tensor_names:\n",
        "                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "                        tensor_name)\n",
        "            if 'detection_masks' in tensor_dict:\n",
        "                # El siguiente procesamiento es solo para una sola imagen\n",
        "                detection_boxes = tf.squeeze(\n",
        "                    tensor_dict['detection_boxes'], [0])\n",
        "                detection_masks = tf.squeeze(\n",
        "                    tensor_dict['detection_masks'], [0])\n",
        "                # Es necesario volver a enmarcar para traducir la máscara de las coordenadas del cuadro a las coordenadas de la imagen y ajustar el tamaño de la imagen.\n",
        "                real_num_detection = tf.cast(\n",
        "                    tensor_dict['num_detections'][0], tf.int32)\n",
        "                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n",
        "                                           real_num_detection, -1])\n",
        "                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n",
        "                                           real_num_detection, -1, -1])\n",
        "                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
        "                detection_masks_reframed = tf.cast(\n",
        "                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "                # Siga la convención agregando nuevamente la dimensión del lote\n",
        "                tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "                    detection_masks_reframed, 0)\n",
        "            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "            # Run inference\n",
        "            output_dict = sess.run(tensor_dict,feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
        "\n",
        "            # todas las salidas son matrices numpy float32, así que convierta los tipos según corresponda\n",
        "            output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
        "            output_dict['detection_classes'] = output_dict['detection_classes'][0].astype(np.uint8)\n",
        "            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "            if 'detection_masks' in output_dict:\n",
        "                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "    return output_dict\n",
        "\n",
        "\n",
        "for image_path in TEST_IMAGE_PATHS:\n",
        "  print(image_path)\n",
        "  image = Image.open(image_path)\n",
        "  # la representación basada en matriz de la imagen se usará más adelante para preparar la imagen resultante con cuadros y etiquetas.\n",
        "  image_np = load_image_into_numpy_array(image)\n",
        "  # Amplíe las dimensiones ya que el modelo espera que las imágenes tengan forma: [1, None, None, 3]\n",
        "  image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "  # deteción actual\n",
        "  output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
        "  # Visualización de los resultados de una detección.\n",
        "  vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "    image_np,\n",
        "    output_dict['detection_boxes'],\n",
        "    output_dict['detection_classes'],\n",
        "    output_dict['detection_scores'],\n",
        "    category_index,\n",
        "    instance_masks=output_dict.get('detection_masks'),\n",
        "    use_normalized_coordinates=True,\n",
        "    line_thickness=8)\n",
        "  plt.figure(figsize=IMAGE_SIZE)\n",
        "  plt.imshow(image_np)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_y2-tR2_6An",
        "colab_type": "text"
      },
      "source": [
        "##Paso #6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwItxQaW_5-o",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAekRi2J_M42",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DEST_DIR='/content/gdrive/My Drive/deteccionDeObjectos/models/research/pretrained_model'\n",
        "fine_tune_checkpoint = os.path.join(\"/content/gdrive/My Drive/deteccionDeObjectos/models/research/pretrained_model\", \"model.ckpt\")\n",
        "#!echo {DEST_DIR}\n",
        "#!ls -alh {DEST_DIR}\n",
        "print(\"fine_tune_checkpoint: \"+fine_tune_checkpoint)\n",
        "print(\"pb_fname: \"+pb_fname)\n",
        "print(\"pipeline_fname: \"+pipeline_fname)\n",
        "print(\"model_dir: \"+model_dir)\n",
        "!ls -alh /content/gdrive/My\\ Drive/deteccionDeObjectos/models/research/training/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcKNaK7j_Mq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python /content/gdrive/My\\ Drive/deteccionDeObjectos/models/research/object_detection/export_tflite_ssd_graph.py \\\n",
        "--pipeline_config_path=/content/gdrive/My\\ Drive/deteccionDeObjectos/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config \\\n",
        "--trained_checkpoint_prefix=/content/gdrive/My\\ Drive/deteccionDeObjectos/models/research/training/model.ckpt-663 \\\n",
        "--output_directory=/content/gdrive/My\\ Drive/deteccionDeObjectos/models/research/tflite \\\n",
        "--add_postprocessing_op=true"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z_62ivI_9ve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"/content/modelo_salvado\")\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_quant_model = converter.convert()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}